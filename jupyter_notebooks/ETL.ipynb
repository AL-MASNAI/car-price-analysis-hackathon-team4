{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD THE NOTEBOOK NAME HERE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write down which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\M4x1m\\\\OneDrive\\\\Dokumente\\\\VS Code\\\\Code Institude'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\M4x1m\\\\OneDrive\\\\Dokumente\\\\VS Code\\\\Code Institude'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Loading the dataset and initial checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset:\n",
        "Use pandas to read the raw car data CSV file into a DataFrame.\n",
        "Check the shape:\n",
        "Display the number of rows and columns in the loaded DataFrame to understand the dataset size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:/vscode-projects/car-price-analysis-hackathon-team4/Data/raw/cars.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mD:/vscode-projects/car-price-analysis-hackathon-team4/Data/raw/cars.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df.shape\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M4x1m\\OneDrive\\Dokumente\\VS Code\\Code Institude\\car-price-analysis-hackathon-team4\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    945\u001b[39m )\n\u001b[32m    946\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M4x1m\\OneDrive\\Dokumente\\VS Code\\Code Institude\\car-price-analysis-hackathon-team4\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    608\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M4x1m\\OneDrive\\Dokumente\\VS Code\\Code Institude\\car-price-analysis-hackathon-team4\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1447\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M4x1m\\OneDrive\\Dokumente\\VS Code\\Code Institude\\car-price-analysis-hackathon-team4\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1704\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1716\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M4x1m\\OneDrive\\Dokumente\\VS Code\\Code Institude\\car-price-analysis-hackathon-team4\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    862\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'D:/vscode-projects/car-price-analysis-hackathon-team4/Data/raw/cars.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('D:/vscode-projects/car-price-analysis-hackathon-team4/Data/raw/cars.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View DataFrame Information:\n",
        "Display a concise summary of the DataFrame, including column names, data types, and non-null counts. This helps to quickly assess the structure and completeness of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preview the Data:\n",
        "Display the first few rows of the DataFrame to get an initial look at the dataset and verify that it loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary Statistics:\n",
        "Generate descriptive statistics for the numerical columns in the DataFrame, such as mean, standard deviation, min, max, and quartiles. This provides a quick overview of the data distribution and helps identify potential outliers or anomalies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List DataFrame Columns:\n",
        "Display all column names in the DataFrame to review the available features and ensure the expected structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for Duplicate Rows:\n",
        "Count the number of duplicate rows in the DataFrame to identify potential data quality issues and ensure the uniqueness of records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List DataFrame Columns:\n",
        "Display all column names in the DataFrame to review the available features and ensure the expected structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract Brand and Model Information:\n",
        "Split the CarName column into separate brand and model columns for more granular analysis.\n",
        "Remove the original CarName column to avoid redundancy, and preview the updated DataFrame to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract brand and model from CarName column\n",
        "df[['brand', 'model']] = df['CarName'].str.split(' ', n=1, expand=True)\n",
        "# drop CarName column\n",
        "df = df.drop('CarName', axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reorder Columns for Clarity:\n",
        "Move the brand and model columns to immediately follow car_ID in the DataFrame.\n",
        "This improves readability and makes it easier to analyze car attributes together.\n",
        "Preview the updated DataFrame to confirm the new column order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reorder columns to place 'brand' and 'model' right after 'car_ID'\n",
        "cols = list(df.columns)\n",
        "car_id_index = cols.index('car_ID')\n",
        "\n",
        "# Remove brand and model from their current positions\n",
        "cols.remove('brand')\n",
        "cols.remove('model')\n",
        "\n",
        "# Insert brand and model right after car_ID\n",
        "cols[car_id_index+1:car_id_index+1] = ['brand', 'model']\n",
        "df = df[cols]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardize Brand Names:\n",
        "Replace typos and inconsistencies in the brand column to ensure all car brands are labeled consistently for analysis and visualization.\n",
        "Display the unique brand names after correction to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize brand names to correct typos and inconsistencies\n",
        "# This ensures all brands are consistently labeled for analysis and visualization\n",
        "brand_corrections = {\n",
        "    'maxda': 'mazda',\n",
        "    'Nissan': 'nissan',\n",
        "    'porcshce': 'porsche',\n",
        "    'toyouta': 'toyota',\n",
        "    'vokswagen': 'volkswagen',\n",
        "    'vw': 'volkswagen',\n",
        "    'alfa-romero': 'alfa-romeo'\n",
        "}\n",
        "df['brand'] = df['brand'].replace(brand_corrections)\n",
        "df['brand'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for Missing Values:\n",
        "Count the number of missing (null) values in each column to identify incomplete data and guide further cleaning steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum() # Check for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle Missing Model Names:\n",
        "Fill any missing values in the model column with 'unknown' to maintain data integrity.\n",
        "Recheck for missing values in all columns to confirm that the issue has been addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['model'] = df['model'].fillna('null') # Fill missing model names with 'null'\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Data Types:\n",
        "Display the data type of each column in the DataFrame to ensure correct formats for analysis and identify any columns that may need conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore Unique Values in Each Column:\n",
        "Print the unique values for every column in the DataFrame to understand the range and categories of data present, and to identify potential issues or patterns for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display unique values for every column\n",
        "for col in df.columns:\n",
        "    print(f'Unique values in {col}:')\n",
        "    print(df[col].unique())\n",
        "    print('-'*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transforming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert Textual Numbers to Integers:\n",
        "Map the text values in the doornumber and cylindernumber columns to their corresponding integer values.\n",
        "This conversion makes the data more suitable for mathematical operations, comparisons, and visualizations.\n",
        "Preview the updated columns to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert 'doornumber' and 'cylindernumber' from text to integers\n",
        "# By mapping these words to their corresponding integer values, the data is more suitable for mathematical operations, comparisons, and visualizations.\n",
        "\n",
        "number_map = {'two': 2, 'four': 4, 'three': 3, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}\n",
        "df['doornumber'] = df['doornumber'].map(number_map)\n",
        "df['cylindernumber'] = df['cylindernumber'].map(number_map)\n",
        "\n",
        "df[['doornumber', 'cylindernumber']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert Price Values to Integers:\n",
        "Round the values in the price column and convert them to integers to ensure consistency and facilitate numerical analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert all price values to integers\n",
        "df['price'] = df['price'].round().astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert Engine Size to Liters:\n",
        "\n",
        "Transform the enginesize column from cubic inches to liters by dividing each value by 60. Then, round the results to two decimal places for consistency and readability. This ensures all engine size values are in a standard metric unit suitable for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['enginesize'] = df['enginesize']/60 # Convert enginesize from cubic inches to liters\n",
        "df['enginesize'] = df['enginesize'].round(2).astype(float)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Outlier Summary Table:\n",
        "\n",
        "Generate a summary table that lists, for each numeric feature, the indices and values of detected outliers. This helps to quickly identify which rows (cars) have unusually high or low values for specific features, supporting further investigation or data cleaning. The table provides a clear overview of outlier distribution across the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate outlier flags using Z-score for each numeric column\n",
        "from scipy.stats import zscore\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "z_scores = df[numeric_cols].apply(zscore)\n",
        "outlier_flags = (abs(z_scores) > 3)\n",
        "\n",
        "# Create a table showing outliers for every column\n",
        "outlier_table = []\n",
        "for col in outlier_flags.columns:\n",
        "    outlier_indices = df.index[outlier_flags[col]].tolist()\n",
        "    outlier_values = df.loc[outlier_flags[col], col].tolist()\n",
        "    outlier_table.append({\n",
        "        'Feature': col,\n",
        "        'Outlier_Indices': outlier_indices,\n",
        "        'Outlier_Values': outlier_values\n",
        "    })\n",
        "\n",
        "outlier_table_df = pd.DataFrame(outlier_table)\n",
        "outlier_table_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize Outliers with Box Plots:\n",
        "\n",
        "Display box plots for the cylindernumber and enginesize features to identify the distribution and spot potential outliers. Box plots provide a clear summary of the data’s spread, median, and extreme values for each feature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['cylindernumber', 'enginesize']\n",
        "plt.figure(figsize=(12, 6))\n",
        "df[features].boxplot()\n",
        "plt.title('Box Plot of Selected Features')\n",
        "plt.ylabel('Value')\n",
        "plt.xticks(rotation=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion: Outliers in the dataset are not random; they cluster in certain features (wheelbase, engine size, cylinder number, price). This is expected in car data, as rare or luxury cars often have extreme values in multiple attributes. They are considered as valid, so they will not be removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# New features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Power-to-weight ratio - provides a more accurate measure of a car's real-world performance than horsepower alone. By dividing horsepower by curb weight, you account for both engine power and vehicle mass. This ratio helps compare cars of different sizes and weights, showing which vehicles are likely to accelerate faster and feel more responsive. It is a key feature for performance analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['power_to_weight'] = df['horsepower'] / df['curbweight'] # Create power-to-weight ratio feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Car volume calculation - provides an estimate of the vehicle's overall physical size. This feature helps comparing cars in terms of interior space, comfort, and cargo capacity. It is useful for understanding how spacious or practical a car is, which can be important for buyers interested in family cars, SUVs, or vehicles with more storage. Including car volume allows for a more comprehensive analysis beyond just performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['car_volume'] = df['carlength'] * df['carwidth'] * df['carheight'] # Create car volume feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mpg ratio - helps comparing a car’s fuel efficiency in city versus highway driving conditions. By dividing city mpg by highway mpg, we can identify vehicles that perform similarly or differently across these environments. A ratio close to 1 means the car is efficient in both settings, while a lower ratio may indicate much better highway efficiency. This feature is useful for understanding real-world fuel consumption patterns and for recommending cars based on typical driving habits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['mpg_ratio'] = df['citympg'] / df['highwaympg'] # Create mpg ratio feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luxury car flag - helps us identify which cars in your dataset are considered luxury based on their price. By setting a threshold at the 75th percentile, we classify the top 25% most expensive cars as luxury. This feature is useful for segmenting the market, analyzing trends, and comparing characteristics between luxury and non-luxury vehicles. It supports targeted analysis and can be valuable for marketing, pricing strategies, or customer recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "luxury_threshold = df['price'].quantile(0.75) # Determine 75th percentile price threshold\n",
        "df['is_luxury'] = (df['price'] > luxury_threshold).astype(int) # Flag cars above threshold as luxury (1) or not (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Standartizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comp = df.copy()\n",
        "comp.drop(columns=['brand',\n",
        "                    'model',\n",
        "                    'carbody',\n",
        "                    'fueltype',\n",
        "                    'enginetype', \n",
        "                    'aspiration', \n",
        "                    'carbody', \n",
        "                    'drivewheel', \n",
        "                    'enginelocation', \n",
        "                    'fuelsystem'], inplace=True)\n",
        "comp.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scoring sytshem for Familie / Citycar\n",
        "\n",
        "symboling - the higher the worse the savety - so a 0 is value 3 and a 1 is -3\n",
        "\n",
        "Doornumer - the more the saver \n",
        "\n",
        "wheelbase - the bigger the worse\n",
        "\n",
        "carwidth - the more the worse \n",
        "\n",
        "cylindernumber - higher the worse\n",
        "\n",
        "enginesize - the more the worse \n",
        "\n",
        "\n",
        "### Scoring sytshem for Offroad \n",
        "symboling - the higher the worse the savety - so a 0 is value 3 and a 1 is -3\n",
        "\n",
        "Doornumer - the more the better\n",
        "\n",
        "wheelbase - the bigger the better\n",
        "\n",
        "cylindernumber - \n",
        "\n",
        "enginesize - \n",
        "\n",
        "\n",
        "### Scoring sytshem for Sportscar\n",
        "symboling - the higher the worse the savety - so a 0 is value 3 and a 1 is -3\n",
        "\n",
        "Doornumer - the more the worse\n",
        "\n",
        "wheelbase - depends (sprectrum slider)\n",
        "\n",
        "cylindernumber - higher is better\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
